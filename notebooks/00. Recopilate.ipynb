{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d4316c",
   "metadata": {},
   "source": [
    "### Extract Local Film Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# --------------- Ruta Modificable Aqu√≠ --------------\n",
    "root = Path(r\"E:\\VIDEOS\\FILME\")\n",
    "out_path = Path(\"filme_report.csv\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "VIDEO_EXTS = {\n",
    "    '.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm',\n",
    "    '.mpg', '.mpeg', '.m4v', '.3gp', '.ts', '.rmvb'\n",
    "}\n",
    "\n",
    "\n",
    "def human_readable_size(nbytes: int) -> str:\n",
    "    if nbytes < 1024:\n",
    "        return f\"{nbytes} B\"\n",
    "    for unit in (\"KB\", \"MB\", \"GB\", \"TB\"):\n",
    "        nbytes /= 1024.0\n",
    "        if nbytes < 1024.0:\n",
    "            return f\"{nbytes:3.1f} {unit}\"\n",
    "    return f\"{nbytes:.1f} PB\"\n",
    "\n",
    "\n",
    "def get_folder_size(folder: Path) -> int:\n",
    "    \"\"\"Suma recursivamente el tama√±o de todos los archivos dentro de una carpeta.\"\"\"\n",
    "    total = 0\n",
    "    for f in folder.rglob(\"*\"):\n",
    "        if f.is_file():\n",
    "            try:\n",
    "                total += f.stat().st_size\n",
    "            except OSError:\n",
    "                pass\n",
    "    return total\n",
    "\n",
    "\n",
    "def examine_films(root: Path):\n",
    "    results = []\n",
    "    folders_with_subfolders = 0\n",
    "\n",
    "    if not root.exists() or not root.is_dir():\n",
    "        raise FileNotFoundError(f\"La carpeta ra√≠z indicada no existe o no es un directorio: {root}\")\n",
    "\n",
    "    for entry in sorted(root.iterdir(), key=lambda p: p.name.lower()):\n",
    "        if not entry.is_dir():\n",
    "            continue\n",
    "\n",
    "        carpeta = entry\n",
    "        archivos = [f for f in carpeta.iterdir() if f.is_file()]\n",
    "        subcarpetas = [d for d in carpeta.iterdir() if d.is_dir()]\n",
    "\n",
    "        num_docs = len(archivos)\n",
    "        nombres_docs = [f.name for f in archivos]\n",
    "\n",
    "        # Detectar archivos de v√≠deo por extensi√≥n\n",
    "        video_files = [f for f in archivos if f.suffix.lower() in VIDEO_EXTS]\n",
    "        num_videos = len(video_files)\n",
    "        nombres_videos = [f.name for f in video_files]\n",
    "\n",
    "        # Tama√±os (bytes y legible)\n",
    "        tama√±os_bytes = []\n",
    "        tama√±os_legibles = []\n",
    "        formatos = []\n",
    "        for f in video_files:\n",
    "            try:\n",
    "                size = f.stat().st_size\n",
    "            except OSError:\n",
    "                size = 0\n",
    "            tama√±os_bytes.append(str(size))\n",
    "            tama√±os_legibles.append(human_readable_size(size))\n",
    "            formatos.append(f.suffix.lower().lstrip('.'))\n",
    "\n",
    "        # Detectar carpeta VIDEO_TS y calcular su tama√±o total\n",
    "        has_videots = None\n",
    "        for d in subcarpetas:\n",
    "            if d.name.lower() == \"video_ts\":\n",
    "                has_videots = d\n",
    "                break\n",
    "\n",
    "        tam_videots_bytes = \"\"\n",
    "        tam_videots_legible = \"\"\n",
    "        if has_videots:\n",
    "            formato_field = \"DVD\"\n",
    "            size_videots = get_folder_size(has_videots)\n",
    "            tam_videots_bytes = str(size_videots)\n",
    "            tam_videots_legible = human_readable_size(size_videots)\n",
    "        else:\n",
    "            # Unir formatos √∫nicos en orden alfab√©tico\n",
    "            unique_formats = sorted(set(formatos))\n",
    "            formato_field = \"; \".join(unique_formats) if unique_formats else \"\"\n",
    "\n",
    "        num_subcarpetas = len(subcarpetas)\n",
    "        nombres_subcarpetas = [d.name for d in subcarpetas]\n",
    "\n",
    "        if num_subcarpetas > 0:\n",
    "            folders_with_subfolders += 1\n",
    "\n",
    "        results.append({\n",
    "            \"CARPETA\": carpeta.name,\n",
    "            \"Numero de documentos\": num_docs,\n",
    "            \"Nombres de documentos\": \"; \".join(nombres_docs),\n",
    "            \"N√∫mero de documentos de tipo video\": num_videos,\n",
    "            \"Nombre de documentos de tipo video\": \"; \".join(nombres_videos),\n",
    "            \"Tama√±o (bytes)\": \"; \".join(tama√±os_bytes),\n",
    "            \"Tama√±o (legible)\": \"; \".join(tama√±os_legibles),\n",
    "            \"Formato de video\": formato_field,\n",
    "            \"Tama√±o VIDEO_TS (bytes)\": tam_videots_bytes,\n",
    "            \"Tama√±o VIDEO_TS (legible)\": tam_videots_legible,\n",
    "            \"Numero de subcarpetas\": num_subcarpetas,\n",
    "            \"Nombre de subcarpetas\": \"; \".join(nombres_subcarpetas),\n",
    "        })\n",
    "\n",
    "    return results, folders_with_subfolders\n",
    "\n",
    "\n",
    "def write_csv(rows, out_path: Path, delimiter=\"|\"):\n",
    "    headers = [\n",
    "        \"CARPETA\",\n",
    "        \"Numero de documentos\",\n",
    "        \"Nombres de documentos\",\n",
    "        \"N√∫mero de documentos de tipo video\",\n",
    "        \"Nombre de documentos de tipo video\",\n",
    "        \"Tama√±o (bytes)\",\n",
    "        \"Tama√±o (legible)\",\n",
    "        \"Formato de video\",\n",
    "        \"Tama√±o VIDEO_TS (bytes)\",\n",
    "        \"Tama√±o VIDEO_TS (legible)\",\n",
    "        \"Numero de subcarpetas\",\n",
    "        \"Nombre de subcarpetas\",\n",
    "    ]\n",
    "    with out_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers, delimiter=delimiter)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        rows, folders_with_subfolders = examine_films(root)\n",
    "        write_csv(rows, out_path)\n",
    "        print(f\"\\n‚úÖ CSV generado en: {out_path.resolve()}\")\n",
    "        print(f\"üìÅ Carpetas con subcarpetas: {folders_with_subfolders}\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429e1a8",
   "metadata": {},
   "source": [
    "### Identify Local Films to Enrich Film Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd88f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "root = Path(r\"E:\\VIDEOS\\FILME\")\n",
    "out_csv = Path(\"filme_metadata.csv\")\n",
    "OMDB_API_KEY = \"http://www.omdbapi.com/?i=tt3896198&apikey=c53c64d6\"\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\\\n",
    "             \"(KHTML, like Gecko) Chrome/117.0 Safari/537.36\"\n",
    "REQUEST_DELAY = 3.0\n",
    "# ----------------------------------------\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": USER_AGENT})\n",
    "\n",
    "\n",
    "def safe_get(url, params=None, timeout=15):\n",
    "    \"\"\"Petici√≥n GET con manejo b√°sico de errores y delays.\"\"\"\n",
    "    try:\n",
    "        r = session.get(url, params=params, timeout=timeout)\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        # print(f\"[WARN] petici√≥n fallida a {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def search_omdb(title, year=None):\n",
    "    \"\"\"\n",
    "    Busca en OMDb por t√≠tulo (y a√±o opcional) y devuelve el JSON si lo encuentra.\n",
    "    \"\"\"\n",
    "    if not OMDB_API_KEY or OMDB_API_KEY == \"TU_OMDB_API_KEY_AQUI\":\n",
    "        return None\n",
    "    params = {\"apikey\": OMDB_API_KEY, \"t\": title}\n",
    "    if year:\n",
    "        params[\"y\"] = year\n",
    "    r = safe_get(\"http://www.omdbapi.com/\", params=params)\n",
    "    if not r:\n",
    "        return None\n",
    "    data = r.json()\n",
    "    if data.get(\"Response\", \"False\") == \"True\":\n",
    "        return data\n",
    "    # fallback: intentar b√∫squeda por s (search) y luego obtener por imdbID\n",
    "    params_search = {\"apikey\": OMDB_API_KEY, \"s\": title}\n",
    "    r2 = safe_get(\"http://www.omdbapi.com/\", params=params_search)\n",
    "    if not r2:\n",
    "        return None\n",
    "    sr = r2.json()\n",
    "    if sr.get(\"Response\") == \"True\" and sr.get(\"Search\"):\n",
    "        first = sr[\"Search\"][0]\n",
    "        imdbid = first.get(\"imdbID\")\n",
    "        r3 = safe_get(\"http://www.omdbapi.com/\", params={\"apikey\": OMDB_API_KEY, \"i\": imdbid, \"plot\": \"short\"})\n",
    "        if r3:\n",
    "            d = r3.json()\n",
    "            if d.get(\"Response\") == \"True\":\n",
    "                return d\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_awards_for_oscars(awards_text):\n",
    "    \"\"\"\n",
    "    Intenta extraer nominaciones y victorias de los Oscars y edici√≥n si aparece.\n",
    "    Devuelve (nominaciones, ganados, edicion_texto)\n",
    "    \"\"\"\n",
    "    if not awards_text:\n",
    "        return \"\", \"\", \"\"\n",
    "    text = awards_text\n",
    "    # buscar 'Oscar' seguido de n√∫meros\n",
    "    nominaciones = \"\"\n",
    "    ganados = \"\"\n",
    "    edicion = \"\"\n",
    "    # ejemplos en OMDb: \"Nominated for 1 Oscar. Another 3 wins & 5 nominations.\"\n",
    "    # buscar \"Nominated for X Oscar\" o \"Won X Oscar\"\n",
    "    m_nom = re.search(r\"Nominated for (\\d+) Oscar\", text)\n",
    "    m_won = re.search(r\"Won (\\d+) Oscar\", text)\n",
    "    if m_nom:\n",
    "        nominaciones = m_nom.group(1)\n",
    "    if m_won:\n",
    "        ganados = m_won.group(1)\n",
    "    # a veces aparece \"Nominated for 2 Oscars. Another 3 wins & 4 nominations.\"\n",
    "    # Tambi√©n intentar buscar \"Oscars\" plural\n",
    "    if not nominaciones:\n",
    "        m_nom2 = re.search(r\"Nominated for (\\d+) Oscars\", text)\n",
    "        if m_nom2:\n",
    "            nominaciones = m_nom2.group(1)\n",
    "    if not ganados:\n",
    "        m_won2 = re.search(r\"Won (\\d+) Oscars\", text)\n",
    "        if m_won2:\n",
    "            ganados = m_won2.group(1)\n",
    "    # edici√≥n: intentar capturar \"Nominated for X Oscar (YEAR?)\" no siempre est√°\n",
    "    # No hay formato est√°ndar; devolvemos texto completo si contiene 'Oscar'\n",
    "    if \"Oscar\" in text:\n",
    "        edicion = text\n",
    "    return nominaciones, ganados, edicion\n",
    "\n",
    "\n",
    "def search_filmaffinity(folder_name):\n",
    "    \"\"\"\n",
    "    Buscar en FilmAffinity el t√≠tulo y devolver (fa_id, fa_rating, fa_synopsis).\n",
    "    M√©todo: usar el buscador de FilmAffinity y tomar el primer resultado.\n",
    "    NOTA: FilmAffinity puede cambiar HTML o bloquear scraping.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = quote_plus(folder_name)\n",
    "        url = f\"https://www.filmaffinity.com/en/search.php?stype=title&stext={query}\"\n",
    "        # en ocasiones el dominio /es/ o sin /en/; probar /en/ para consistencia\n",
    "        r = safe_get(url)\n",
    "        if not r:\n",
    "            # intentar versi√≥n sin /en/\n",
    "            url2 = f\"https://www.filmaffinity.com/search.php?stype=title&stext={query}\"\n",
    "            r = safe_get(url2)\n",
    "            if not r:\n",
    "                return \"\", \"\", \"\"\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        # buscar primer resultado en la lista\n",
    "        # en la p√°gina: resultados suelen estar en .movie-card / .fa-search-result / .mc-title\n",
    "        link = soup.select_one(\"div.movie-card a[href]\") or soup.select_one(\"div.mc-title a[href]\") or soup.select_one(\"a.movie-link[href]\")\n",
    "        if not link:\n",
    "            # intentar otro selector general\n",
    "            link = soup.select_one(\"a[href*='film']\")  # enlace que contenga 'film'\n",
    "        if not link:\n",
    "            return \"\", \"\", \"\"\n",
    "        href = link.get(\"href\")\n",
    "        # obtener id si est√° en la URL, ej: /en/film123456.html o /film123456.html\n",
    "        m = re.search(r\"film(\\d+)\\.html\", href)\n",
    "        fa_id = m.group(1) if m else href\n",
    "        # solicitar la p√°gina del film\n",
    "        film_url = href if href.startswith(\"http\") else (\"https://www.filmaffinity.com\" + href)\n",
    "        r2 = safe_get(film_url)\n",
    "        if not r2:\n",
    "            return fa_id, \"\", \"\"\n",
    "        s2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "        # rating: puede estar en el selector .rating .average or span[itemprop=\"ratingValue\"]\n",
    "        rating_el = s2.select_one('div.avg-rating') or s2.select_one('div.rating') or s2.select_one('span[itemprop=\"ratingValue\"]')\n",
    "        rating = \"\"\n",
    "        if rating_el:\n",
    "            rating = rating_el.get_text(strip=True)\n",
    "        # sinopsis: buscar #synopsis or .synopsis or #sinopsis\n",
    "        sinopsis_el = s2.select_one(\"#synopsis\") or s2.select_one(\"div.synopsis\") or s2.select_one(\"div#movie-synopsis\")\n",
    "        sinopsis = \"\"\n",
    "        if sinopsis_el:\n",
    "            sinopsis = sinopsis_el.get_text(\" \", strip=True)\n",
    "        # versi√≥n en espa√±ol: FilmAffinity muestra t√≠tulo original y t√≠tulo espa√±ol en la misma p√°gina; extraer t√≠tulo original si hay\n",
    "        return fa_id, rating, sinopsis\n",
    "    except Exception:\n",
    "        return \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "def search_rottentomatoes(folder_name):\n",
    "    \"\"\"\n",
    "    Busca en RottenTomatoes y devuelve (rt_id, tomatometer, popcornmeter?).\n",
    "    Usamos la b√∫squeda p√∫blica: https://www.rottentomatoes.com/search?search=...\n",
    "    \"\"\"\n",
    "    try:\n",
    "        q = quote_plus(folder_name)\n",
    "        url = f\"https://www.rottentomatoes.com/search?search={q}\"\n",
    "        r = safe_get(url)\n",
    "        if not r:\n",
    "            return \"\", \"\", \"\"\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        # La estructura JS a veces rellena resultados; intentar leer resultados \"search-page-media-row\" o links a /m/slug\n",
    "        link = soup.select_one(\"search-page-media-row a\") or soup.select_one(\"a[href^='/m/']\") or soup.select_one(\"a[href^='/m/'], a[href^='/movies/']\")\n",
    "        if not link:\n",
    "            return \"\", \"\", \"\"\n",
    "        href = link.get(\"href\")\n",
    "        rt_id = href\n",
    "        film_url = href if href.startswith(\"http\") else (\"https://www.rottentomatoes.com\" + href)\n",
    "        r2 = safe_get(film_url)\n",
    "        if not r2:\n",
    "            return rt_id, \"\", \"\"\n",
    "        s2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "        # Tomatometer: selector puede ser score-board with data-meter or scoreBoard\n",
    "        tm = \"\"\n",
    "        # Buscamos elementos con class 'mop-ratings-wrap__percentage' o 'score-board' data-meter\n",
    "        score_el = s2.select_one(\".mop-ratings-wrap__percentage\") or s2.select_one(\"score-board\")\n",
    "        if score_el:\n",
    "            tm_text = score_el.get_text(\" \", strip=True)\n",
    "            m = re.search(r\"(\\d+)%\", tm_text)\n",
    "            if m:\n",
    "                tm = m.group(1)\n",
    "        # si score-board tiene atributo data-meter\n",
    "        sb = s2.select_one(\"score-board\")\n",
    "        if sb and not tm:\n",
    "            tm = sb.get(\"tomatometerscore\") or sb.get(\"tomatometerscore\")\n",
    "        return rt_id, tm, \"\"\n",
    "    except Exception:\n",
    "        return \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "def search_popcornmeter(folder_name):\n",
    "    \"\"\"\n",
    "    Intento simple para PopcornMeter (si existe); devolver el id o puntuaci√≥n si se encuentra.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        q = quote_plus(folder_name)\n",
    "        url = f\"https://www.popcornmeter.com/search?search={q}\"\n",
    "        r = safe_get(url)\n",
    "        if not r:\n",
    "            return \"\", \"\"\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        link = soup.select_one(\"a[href*='/movie/']\")\n",
    "        if not link:\n",
    "            return \"\", \"\"\n",
    "        href = link.get(\"href\")\n",
    "        # la puntuaci√≥n puede aparecer en .popcornmeter-score o similar\n",
    "        r2 = safe_get(href if href.startswith(\"http\") else (\"https://www.popcornmeter.com\" + href))\n",
    "        if not r2:\n",
    "            return href, \"\"\n",
    "        s2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "        score_el = s2.select_one(\".score\") or s2.select_one(\".rating-value\")\n",
    "        score = score_el.get_text(strip=True) if score_el else \"\"\n",
    "        return href, score\n",
    "    except Exception:\n",
    "        return \"\", \"\"\n",
    "\n",
    "\n",
    "def collect_for_folder(folder: Path):\n",
    "    \"\"\"\n",
    "    Dada la carpeta de la pel√≠cula, retorna un dict con los campos solicitados.\n",
    "    \"\"\"\n",
    "    folder_name = folder.name\n",
    "    row = {\n",
    "        \"T√≠tulo original\": \"\",\n",
    "        \"T√≠tulo en espa√±ol\": \"\",\n",
    "        \"Direcci√≥n\": \"\",\n",
    "        \"Gui√≥n\": \"\",\n",
    "        \"Pa√≠s\": \"\",\n",
    "        \"a√±o\": \"\",\n",
    "        \"Duraci√≥n\": \"\",\n",
    "        \"Lista de G√©neros\": \"\",\n",
    "        \"Puntuaci√≥n filmaffinity\": \"\",\n",
    "        \"Puntuaci√≥n IMDB\": \"\",\n",
    "        \"Tomatometer\": \"\",\n",
    "        \"Popcornmeter\": \"\",\n",
    "        \"Lista de actores\": \"\",\n",
    "        \"Nominaciones Oscar\": \"\",\n",
    "        \"Oscar ganados\": \"\",\n",
    "        \"Edici√≥n Oscar\": \"\",\n",
    "        \"Sinopsis filmaffinity\": \"\",\n",
    "        \"ID OMDb\": \"\",\n",
    "        \"ID IMDB\": \"\",\n",
    "        \"ID filmaffinity\": \"\",\n",
    "        \"ID rottentomatoes\": \"\",\n",
    "        \"Nombre de la carpeta\": folder_name,\n",
    "    }\n",
    "\n",
    "    # 1) Intentar OMDb (clave obligatoria)\n",
    "    omdb_data = search_omdb(folder_name)\n",
    "    if omdb_data:\n",
    "        # rellenar campos desde OMDb\n",
    "        row[\"T√≠tulo original\"] = omdb_data.get(\"Title\", \"\")\n",
    "        # OMDb no distingue t√≠tulo en espa√±ol; dejar T√≠tulo en espa√±ol vac√≠o si no hay\n",
    "        row[\"T√≠tulo en espa√±ol\"] = \"\"  # opcional: podr√≠amos intentar traducir o buscar en FilmAffinity\n",
    "        row[\"Direcci√≥n\"] = omdb_data.get(\"Director\", \"\")\n",
    "        row[\"Gui√≥n\"] = omdb_data.get(\"Writer\", \"\")\n",
    "        row[\"Pa√≠s\"] = omdb_data.get(\"Country\", \"\")\n",
    "        row[\"a√±o\"] = omdb_data.get(\"Year\", \"\")\n",
    "        row[\"Duraci√≥n\"] = omdb_data.get(\"Runtime\", \"\")\n",
    "        row[\"Lista de G√©neros\"] = omdb_data.get(\"Genre\", \"\")\n",
    "        # IMDb rating\n",
    "        row[\"Puntuaci√≥n IMDB\"] = omdb_data.get(\"imdbRating\", \"\")\n",
    "        row[\"Lista de actores\"] = omdb_data.get(\"Actors\", \"\")\n",
    "        # IMDb ID\n",
    "        row[\"ID IMDB\"] = omdb_data.get(\"imdbID\", \"\")\n",
    "        # OMDb ID: no tiene id propio, usaremos imdbID como referencia\n",
    "        row[\"ID OMDb\"] = row[\"ID IMDB\"]\n",
    "        # Awards (para Oscars)\n",
    "        nomin, gan, ed = parse_awards_for_oscars(omdb_data.get(\"Awards\", \"\"))\n",
    "        row[\"Nominaciones Oscar\"] = nomin\n",
    "        row[\"Oscar ganados\"] = gan\n",
    "        row[\"Edici√≥n Oscar\"] = ed\n",
    "\n",
    "    # 2) FilmAffinity (scrape)\n",
    "    fa_id, fa_rating, fa_synopsis = search_filmaffinity(folder_name)\n",
    "    if fa_id:\n",
    "        row[\"ID filmaffinity\"] = fa_id\n",
    "    if fa_rating:\n",
    "        row[\"Puntuaci√≥n filmaffinity\"] = fa_rating\n",
    "    if fa_synopsis:\n",
    "        row[\"Sinopsis filmaffinity\"] = fa_synopsis\n",
    "\n",
    "    # 3) RottenTomatoes\n",
    "    rt_id, tomatometer, _ = search_rottentomatoes(folder_name)\n",
    "    if rt_id:\n",
    "        row[\"ID rottentomatoes\"] = rt_id\n",
    "    if tomatometer:\n",
    "        row[\"Tomatometer\"] = tomatometer\n",
    "\n",
    "    # 4) PopcornMeter\n",
    "    pcm_id, pcm_score = search_popcornmeter(folder_name)\n",
    "    if pcm_score:\n",
    "        row[\"Popcornmeter\"] = pcm_score\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not root.exists() or not root.is_dir():\n",
    "        print(f\"[ERROR] La ruta root no existe: {root}\")\n",
    "        return\n",
    "\n",
    "    headers = [\n",
    "        \"T√≠tulo original\", \"T√≠tulo en espa√±ol\", \"Direcci√≥n\", \"Gui√≥n\", \"Pa√≠s\", \"a√±o\",\n",
    "        \"Duraci√≥n\", \"Lista de G√©neros\", \"Puntuaci√≥n filmaffinity\", \"Puntuaci√≥n IMDB\",\n",
    "        \"Tomatometer\", \"Popcornmeter\", \"Lista de actores\", \"Nominaciones Oscar\",\n",
    "        \"Oscar ganados\", \"Edici√≥n Oscar\", \"Sinopsis filmaffinity\",\n",
    "        \"ID OMDb\", \"ID IMDB\", \"ID filmaffinity\", \"ID rottentomatoes\", \"Nombre de la carpeta\"\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "    for entry in sorted(root.iterdir(), key=lambda p: p.name.lower()):\n",
    "        if not entry.is_dir():\n",
    "            continue\n",
    "        try:\n",
    "            print(f\"Procesando: {entry.name}\")\n",
    "            r = collect_for_folder(entry)\n",
    "            rows.append(r)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] fallo procesando {entry.name}: {e}\")\n",
    "\n",
    "    # escribir CSV\n",
    "    with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers, delimiter=\"|\")\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    print(f\"CSV generado: {out_csv.resolve()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
